<!DOCTYPE html>
<html>
<head>
  <title>MediaPipe JS + Image Sonification (Mirrored)</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <style>
    body { margin: 0; background: black; font-family: sans-serif; display: flex; flex-direction: row; justify-content: center; align-items: flex-start; gap: 20px; padding: 20px; }
    #container { display: flex; flex-direction: row; gap: 20px; }
    .panel { position: relative; width: 640px; height: 480px; }
    canvas, video, img { position: absolute; top: 0; left: 0; width: 640px; height: 480px; }
    video { transform: scaleX(-1); } /* Mirror the video */
    #output_canvas { transform: scaleX(-1); } /* Mirror the output canvas */
    #upload { position: absolute; top: 10px; left: 10px; z-index: 3; background: white; padding: 6px; border-radius: 5px; }
    .controls { position: absolute; top: 10px; right: 10px; z-index: 3; background: rgba(255,255,255,0.7); padding: 10px; border-radius: 5px; }
  </style>
</head>
<body>
  <input type="file" id="upload" accept="image/*">
  <div id="container">
    <div class="panel">
      <canvas id="imageCanvas"></canvas>
      <canvas id="imageOverlay" style="z-index:2;"></canvas>
      <img id="inputImage" crossorigin="anonymous">
      <div class="controls">
        <label for="frequency-range">Frequency Range:</label>
        <input type="range" id="min-freq" min="100" max="500" value="200" step="10">
        <span id="min-freq-value">200</span> Hz
        <input type="range" id="max-freq" min="500" max="2000" value="700" step="10">
        <span id="max-freq-value">700</span> Hz
        <br><br>
        <label for="volume-range">Volume Range:</label>
        <input type="range" id="min-vol" min="0.00" max="0.30" value="0.00" step="0.01">
        <span id="min-vol-value">0.00</span>
        <input type="range" id="max-vol" min="0.30" max="1.00" value="0.30" step="0.01">
        <span id="max-vol-value">1.00</span>
      </div>
    </div>
    <div class="panel">
      <video id="input_video" playsinline muted autoplay></video>
      <canvas id="output_canvas"></canvas>
    </div>
  </div>

  <script>
    const videoElement = document.getElementById('input_video');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');
    const imgCanvas = document.getElementById('imageCanvas');
    const imgCtx = imgCanvas.getContext('2d');
    const overlayCanvas = document.getElementById('imageOverlay');
    const overlayCtx = overlayCanvas.getContext('2d');
    const inputImage = document.getElementById('inputImage');
    
    const minFreqSlider = document.getElementById('min-freq');
    const maxFreqSlider = document.getElementById('max-freq');
    const minFreqValue = document.getElementById('min-freq-value');
    const maxFreqValue = document.getElementById('max-freq-value');

    const minVolSlider = document.getElementById('min-vol');
    const maxVolSlider = document.getElementById('max-vol');
    const minVolValue = document.getElementById('min-vol-value');
    const maxVolValue = document.getElementById('max-vol-value');

    let grayscaleData = null;

    let minFreq = 200;
    let maxFreq = 700;

    // Update frequency range values
    minFreqSlider.addEventListener('input', function() {
      minFreq = parseInt(this.value);
      minFreqValue.textContent = minFreq;
    });

    maxFreqSlider.addEventListener('input', function() {
      maxFreq = parseInt(this.value);
      maxFreqValue.textContent = maxFreq;
    });

    let minVol = 0.00;
    let maxVol = 0.30;

    // Update volume range values
    minVolSlider.addEventListener('input', function() {
      minVol = parseFloat(this.value);
      minVolValue.textContent = minVol;
    });

    maxVolSlider.addEventListener('input', function() {
      maxVol = parseFloat(this.value);
      maxVolValue.textContent = maxVol;
    });
  
    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });

    hands.setOptions({
      maxNumHands: 2,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.7
    });

    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    let oscillator = null;
    let gainNode = null;

    function playFrequency(freq, volume = 0.5) {
      if (!oscillator) {
        oscillator = audioCtx.createOscillator();
        gainNode = audioCtx.createGain();
        
        oscillator.type = 'sine';
        oscillator.connect(gainNode);
        gainNode.connect(audioCtx.destination);
        
        oscillator.start();
      }
      
      gainNode.gain.setValueAtTime(volume, audioCtx.currentTime);
      oscillator.frequency.setValueAtTime(freq, audioCtx.currentTime);
    }

    function stopFrequency() {
      if (oscillator) {
        gainNode.gain.setValueAtTime(gainNode.gain.value, audioCtx.currentTime);
        gainNode.gain.exponentialRampToValueAtTime(0.001, audioCtx.currentTime + 0.1);
        
        setTimeout(() => {
          oscillator.stop();
          oscillator.disconnect();
          gainNode.disconnect();
          oscillator = null;
          gainNode = null;
        }, 100);
      }
    }

    hands.onResults(results => {
      // Webcam canvas - note we're not mirroring in the drawing code since the CSS handles it
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

      // Image canvas and overlay
      imgCtx.clearRect(0, 0, imgCanvas.width, imgCanvas.height);
      imgCtx.drawImage(inputImage, 0, 0, imgCanvas.width, imgCanvas.height);
      overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

      let handDetected = false;

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        handDetected = true;
        for (const handLms of results.multiHandLandmarks) {
          // Draw hand landmarks on webcam view
          drawConnectors(canvasCtx, handLms, HAND_CONNECTIONS, {color: '#00FF00', lineWidth: 2});
          drawLandmarks(canvasCtx, handLms, {color: '#FF0000', lineWidth: 1});
          
          // Draw hand landmarks on image overlay
          // For the image overlay, we need to mirror the x-coordinate to match hand movement
          const mirroredHandLms = handLms.map(landmark => {
            return {
              x: 1 - landmark.x, // Mirror the x coordinate
              y: landmark.y,
              z: landmark.z
            };
          });
          
          drawConnectors(overlayCtx, mirroredHandLms, HAND_CONNECTIONS, {color: '#00FF00', lineWidth: 2});
          drawLandmarks(overlayCtx, mirroredHandLms, {color: '#FF0000', lineWidth: 1});

          // Use index finger tip (landmark 8) for sonification
          const x = mirroredHandLms[8].x * overlayCanvas.width;
          const y = mirroredHandLms[8].y * overlayCanvas.height;
          const boxSize = 20;
          
          // Draw targeting box
          overlayCtx.strokeStyle = 'lime';
          overlayCtx.lineWidth = 2;
          overlayCtx.strokeRect(x - boxSize/2, y - boxSize/2, boxSize, boxSize);

          if (grayscaleData) {
            const pixelX = Math.floor(x);
            const pixelY = Math.floor(y);
            
            if (pixelX >= 0 && pixelX < overlayCanvas.width && pixelY >= 0 && pixelY < overlayCanvas.height) {
              const i = (pixelY * overlayCanvas.width + pixelX) * 4;
              const hue = grayscaleData.data[i];
              const freq = minFreq + (hue / 255) * (maxFreq - minFreq);
              
              const brightness = grayscaleData.data[i + 2];
              const volume = minVol + (brightness / 255) * (maxVol - minVol);
              playFrequency(freq, volume);
              
              // Display frequency info
              overlayCtx.fillStyle = 'white';
              overlayCtx.fillRect(x + 10, y - 30, 80, 20);
              overlayCtx.fillStyle = 'black';
              overlayCtx.font = '12px sans-serif';
              overlayCtx.fillText(`${Math.round(freq)} Hz`, x + 15, y - 15);
            }
          }
        }
      }

      if (!handDetected) stopFrequency();

      canvasCtx.restore();
    });

    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await hands.send({image: videoElement});
      },
      width: 640,
      height: 480
    });
    camera.start();

    document.getElementById('upload').addEventListener('change', (e) => {
      const file = e.target.files[0];
      if (file) {
        const reader = new FileReader();
        reader.onload = function(event) {
          inputImage.onload = function() {
            imgCtx.drawImage(inputImage, 0, 0, imgCanvas.width, imgCanvas.height);
            
            // Create grayscale version for sonification
            grayscaleData = imgCtx.getImageData(0, 0, imgCanvas.width, imgCanvas.height);
            const data = grayscaleData.data;
            
            // Convert to HSV for sonification accuracy
            for (let i = 0; i < data.length; i += 4) {
              const r = data[i] / 255;
              const g = data[i + 1] / 255;
              const b = data[i + 2] / 255;

              const cmax = Math.max(r, g, b);
              const cmin = Math.min(r, g, b);
              const delta = cmax - cmin;

              let h = 0;
              if (delta !== 0) {
                if (cmax === r) {
                  h = 60 * (((g - b) / delta) % 6);
                } else if (cmax === g) {
                  h = 60 * ((b - r) / delta + 2);
                } else {
                  h = 60 * ((r - g) / delta + 4);
                }
              }
              if (h < 0) h += 360;

              const v = cmax;
              const hByte = Math.round((h / 360) * 255);
              const vByte = Math.round(v * 255);

              // Store hue and value into separate channels (e.g., red = hue, green = value)
              data[i]     = hByte;   // Red channel holds hue
              data[i + 1] = hByte;   // Grenn channel holds hue
              data[i + 2] = vByte;   // Blue channel holds value
            }
          };
          inputImage.src = event.target.result;
        };
        reader.readAsDataURL(file);
      }
    });

    // Initial setup - ensure canvas sizes match
    function setupCanvasSizes() {
      const width = 640;
      const height = 480;
      
      [canvasElement, imgCanvas, overlayCanvas].forEach(canvas => {
        canvas.width = width;
        canvas.height = height;
      });
    }
    
    setupCanvasSizes();
    
    // Handle window resize
    window.addEventListener('resize', setupCanvasSizes);
  </script>
</body>
</html>